# [The Prime Number Conspiracy: The Biggest Ideas in Math from *Quanta*][homepage], edited by Thomas Lin, The MIT Press (2018)

[Quanta Magazine][quanta_magazine],
 [Alice and Bob Meet the Wall of Fire: The Biggest Ideas in Science from *Quanta*][alice_and_bob_meet_the_wall_of_fire] (2018)<br>
many Fields medalists

[homepage]: https://mitpress.mit.edu/books/prime-number-conspiracy
[quanta_magazine]: https://www.quantamagazine.org/
[alice_and_bob_meet_the_wall_of_fire]: https://mitpress.mit.edu/books/alice-and-bob-meet-wall-fire

## FOREWORD by JAmes Gleick

David Foster Wallace worries that anyone writing about mathematics must bear in
 mind the wide variability in readers' prior knowledge.<br>
Some of the greatest problems are also some of the oldest.<br>
As Kevin Hartnett reports, the geometry of random walks may apply as well to
 quantum strings as it does to bacterial colonies. Mathematicians studying
 "periods of motives" are drawing links between algebraic geometry and the
 Feynman diagrams favored by particle physicists. ... Indeed, mathematics and
 quantum theory are cross-pollinating in unexptected ways. The mathematician
 Svitlana Mayboroda is using the "landscape function" to perform quantum
 simulations of how electrons are localized in disordered materials---a
 breakthrough that may boost the efficiency of LEDs. Other mathematicians are
 looking at the evolution of quantum states in quasicrystals. The advantage of
 the quantum language, as Robbert Dijkgraaf sees it, is that its "holistic
 approach" considers all the possibilities of a system as one ensemble.

## INTRODUCTION by Thomas Lin

The story of *Quanta* began in 2012, just weeks after the Higgs
 announcement.<br>
We trust readers, whether they have a science background or not, to be
 intellectually curious enough to want to know more, so we give you more.

# I WHAT'S SO SPECIAL ABOUT PRIME NUMBERS?

## (1.) UNHERALDED MATHEMATICIAN BRIDGES THE PRIME GAP by Erica Klarreich

Because prime numbers are fundamentally connected with multiplication,
 understanding their additive properties can be tricky (twin primes conjecture
 and Goldbach conjecture).<br>
Zhang's paper (2013) shows that there is some number *N* smaller than 70 million
 such that there are infinitely many pairs of primes that differ by *N*.
 
## (2.) TOGETHER AND ALONE, CLOSING THE PRIME GAP by Erica Klarreich

Other mathematicians quickly realized that it should be possible to push this
 separation bound quite a bit lower, although not all the way down to two.<br>
Maynard's approach applies not just to pairs of primes, but to triples,
 quadruples and larger collections of primes.<br>
Finding the richest fishing grounds for prime numbers ended up being a problem
 in "calculus of variations," a generalization of calculus.

## (3.) KAISA MATOMÄKI DREAMS OF PRIME by Kevin Hartnett

One of the most fundamental theorems in analytic number theory is the prime
 number theorem, which says that the number of primes up to *x* is about
 *x*/log(*x*). the Riemann zeta function is profoundly connected to the
 distribution of prime numbers. This is known to be equivalent to the fact that
 roughly half of the numbers up to *x* have an even number of prime factors and
 half of the numbers have an odd number of prime factors. It's not obvious that
 the two are equivalent, but it's known that they are equivalent because of
 facts related to the zeros of the Riemann zeta function.<br>
We got these averages of multiplicative functions from very short intervals, and
 it has turned out to be very useful for other things. It was thought that they
 are morally equivalent, having the same difficulty, but it turns out they are
 not.

## (4.) MATHEMATICIANS DISCOVER PRIME CONSPIRACY by Erica Klarreich

Two mathematicians have uncovered a simple, previously unnoticed property of
 prime numbers: It seems they have decided preferences about the final digits of
 the primes that immediately follow them.<br>
These simple coin-tossing models (refinements of Cramér's model) tend to be very
 useful rules of thumb about how prime numbers behave. They accurately predict,
 among other things, that prime numbers shouldn't care what their final digit
 is.<br>
Most mathematicians believe the twin primes conjecture not so much because they
 keep finding more twin primes, but because the number of twin primes they've
 found fits so neatly with what the prime k-tuples conjecture predicts. In a
 similar way, Soundararajan and Lemke Oliver have found that the biases they
 uncovered in consecutive primes come very close to what the prime k-tuples
 conjecture predicts.

# II IS MATH THE UNIVERSAL LANGUAGE OF NATURE?

## (5.) MATHEMETICIANS CHASE MOONSHINE'S SHADOW by Erica Klarreich

Strangely enough, the first important coefficient of the *j*-function, one of
 the most fundamental objects in number theory, is 196,884, which McKay
 instantly recognized as the sum of the monster group's first two special
 dimensions. Borcherds, eventually earning a Fields Medal for this work, proved
 that there was a bridge between the two distant realms of mathematics in which
 the monster and the *j*-function live: namely, string theory, the counterintuitive idea that the universe has tiny hidden dimensions, too small to measure, in which strings vibrate to produce the physical effects we experience at the macroscopic scale. In March 2015, researchers posted a paper on arxiv.org presenting a numerical proof of the so-called Umbral Moonshine Conjecture, formulated in 2012, which proposes that in addition to monstrous moonshine, there are 23 other moonshines: mysterious correspondences between the dimensions of a symmetry group on the one hand, and the coefficients of a special function on the other.<br>
While most simple finite groups fell into natural categories, there were 26
 oddballs that defied categorization. Of these, the biggest, and the last to be
 discovered, was the monster.<br>
The *j*-function belongs to a special class of functions whose graphs have
 repeating patterns similar to M. C. Escher's tessellation of a disk with angels
 and devils, which shrink ever smaller as they approach the outer boundary.
 These "modular" functions are the heroes of number theory, playing a crucial
 role, for instance, in Andrew Wiles' 1994 proof of Fermat's Last Theorem
 ("Modular Elliptic Curves and Fermat's Last Theorem"). Any time you hear about
 a striking result in number theory, there's a high chance that it's really a
 statement about modular forms.<br>
In 1920, as Ramanujan lay dying in India at age 32, he wrote Hardy another
 letter saying that he had discovered what he called "mock theta" functions,
 which entered into mathematics "beautifully." He listed 17 examples of these
 functions, but didn't explain what they had in common. Sander Zwegers figured
 out in 2002 that they are all examples of what came to be known as mock modular
 forms. For each of these moonshines, the researchers conjectured, there is a
 string theory like the one in monstrous moonshine, in which the mock modular
 form counts the string states and the group captures the model's symmetry.<br>
Physicists are also excited about a highly conjectural connection between
 moonshine and quantum gravity, the as-yet-undiscovered theory that will unite
 general relativity and quantum mechanics. The physicist Edward Witten
 speculated that the string theory in monstrous moonshine should offer a way to
 construct a model of three-dimensional quantum theory, in which 194 natural
 categories of elements in the monster group correspond to 194 classes of black
 holes.

## (6.) IN MYSTERIOUS PATTERN, MATH AND NATURE CONVERGE by Natalie Wolchover

Scientists now believe the widespread phenomenon, known as "universality," stems
 from an underlying connection to mathematics, and it helping them to model
 complex systems from the internet to Earth's climate. Each of these systems has
 a spectrum---a sequence like a bar code representing data such as enery levels,
 zeta zeros, bus departure times or signal speeds. This find balance between
 chaos and order, which is defined by a precise formula, also appears in a
 purely mathematical setting: It defines the spacing between the eigenvalues, or
 solutions, of a vast matrix filled with random numbers. "It seems to be a law
 of nature," said Van Vu, with Terence Tao, has proven universality for a broad
 class of random matrices. Wigner's hypothesis asserts that all complex,
 correlated systems exhibit universality, from a crystal lattice to the
 internet. This means you can use a random matrix to model it.<br>
The spectral measure of a mosaic of melt ponds, taken from a helicopter, or a
 similar measurement taken of a sample of sea ice in an ice core, instantly
 exposes the state of either system. Researchers have found that the spectrum of
 a dense, healthy bone exhibits universality, while that of a porous,
 osteoporotic bone does not. Every quantum system is governed by a matrix
 representing the total enery of the system, and the eigenvalues of the matrix
 are the energy levels of the quantum system. Another mystery is that spectrum
 of zeros of the Riemann zeta function exhibits universality. Some think there
 may be a matrix underlying the Riemann zeta function that is complex and
 correlated enough to exhibit universality.

## (7.) AT THE FAR ENDS OF A NEW UNIVERSAL LAW by Natalie Wolchover

Systems of many interacting components---be they species, integers or subatomic
 particles---kept producing the same statistical curve, which had been known as
 the Tracy-Widom distribution. This puzzling curve seemed to be the complex
 cousin of the familiar bell curve, or Gaussian distribution. Like the Gaussian,
 the Tracy-Widom distribution exhibits "universality." When uncovered, universal
 laws like the Tracy-Widom distribution enable researchers to accurately model
 complex systems whose inner workings they know little about, like financial
 markets, exotic phases of matter or the internet. They realized the
 universality of the Tracy-Widom distribution could be related to the
 universality of phase transitions---event such as water freezing into ice,
 graphite becoming diamond and ordinary metals transforming into strange
 superconductors.<br>
Researchers had already discovered that the *N* eigenvalues of a "random matrix"
 tend to space apart along the real number line according to a distinct pattern,
 with the largest eigenvalue typically located at or near √(2*N*). The
 distribution dropped off at a rate related to the number of eigenvalues, *N*
 (weak-coupling phase); (strong-coupling phase) on the left, it tapered off more
 quickly, as a function of *N*<sup>2</sup>.

## (8.) A BIRD'S-EYE VIEW OF NATURE's HIDDEN ORDER by Natalie Wolchover

Beyond bird eyes, hyperuniformity is found in materials called quasicrystals, as
 well as in mathematical matrices full of random numbers, the large-scale
 structure of the universe, quantum ensembles and soft-matter systems like
 emulsions and colloids.<br>
Physicists reported that dense hyperuniform materials can be made transparent,
 whereas uncorrelated disordered materials with the same density would be
 opaque. The hidden order in the particles' relative positions causes their
 scattered light to interfere and cancel out.

## (9.) A UNIFIED THEORY OF RANDOMNESS by Kevin Hartnett

Yet in work over the past few years, Sheffield and his frequent collaborator,
 Jason Miller, have shown that these random shapes can be categorized into
 various classes. Their work forms the beginning of a unified theory of
 geometric randomness.<br>
In the 1980s, physicist Alexander Polyakov came up with a way of describing
 these surfaces that came to be called Liouville quantum gravity (LQG). It
 provided an incomplete but still useful view of random two-dimensional
 surfaces. In parallel, another model, called the Brownian map, provided a
 different way to study random two-dimensional surfaces. Where LQG facilitates
 calculation about area, the Brownian map has a structure that allows
 researchers to calculate distances between points. Thanks to works by Schramm
 and by Smirnov, Sheffield and Miller knew that when kappa equals 6, SLE
 (Schramm-Loewner evolution) curves follow the trajectory of a kind of "blind
 explorer" who marks her path by constructing a trail as she goes.<br>
The information possessed by a blind explorer at any time about the outer
 unexplored region of the random surface was exactly the same as the information
 possessed by a bacterial colony.

## (10.) STRANGE NUMBERS FOUND IN PARTICLE COLLISIONS by Kevin Hartnett

It has to do with the strange fact that the values calculated from Feynman
 diagrams seem to exactly match some of the most important numbers, called
 "periods of motives",  that crop up in a branch of mathematics known as
 albegraic geometry---which studies the geometric forms of polynomial
 equations. The same answer---the unique thing at the center of all these
 cohomology theories---was what Grothendieck called a "motive." Motives are in a
 sense the fundamental building blocks of polynomial equations. "Once you know
 the periods, which are specific numbers, that's almost the same as knowing the
 motive itself," said Minhyong Kim.

## (11.) QUANTUM QUESTIONS INSPIRE NEW MATH by Robbert Dijkgraaf

A striking example of the magic of quantum theory is mirror symmetry---a truly
 astonishing equivalence of spaces that has revolutionized geometry. The first
 and most famous example of such an equivalence is the well-known particle-wave
 duality that states that every quantum particle can be considered both as a
 particle and as a wave. The two sides of mirror symmetry offer dual and equally
 valid persepctives on "quantum geometry."<br>
Within quantum theory it makes perfect sense to combine the numbers of curves of
 all degrees into a single elegant function. Assembled in this way, it has a
 straightforward physical interpretation.

# III HOW ARE SURPRISING PROOFS DISCOVERED?

## (12.) A PATH LESS TAKEN TO THE PEAK OF THE MATH WORLD by Kevin Hartnett

June Huh story<br>
The total number of colorings will be all options multiplied together. That
 equation is called the chromatic polynomial for this graph. The absolute value
 of the coefficients of each term has two properties in particular. The first is
 that it's "unimodal," meaning it only peaks once, and before that peak the
 sequence only ever rises, and after that peak it only ever falls. The second
 property is that the sequence of coefficients is "log concave," meaning that
 any three consecutive numbers in the sequence follow this rule: The product of
 the outside two numbers is less than the square of the middle number. That this
 fact always holds is called "Read's conjecture."<br>
The chromatic polynomial of the rectangle is equal to the chromatic polynomial
 of the rectangle with one edge deleted minus the chromatic polynomial of the
 triangle. The chromatic polynomial for any graph can be defined in terms of the
 chromatic polynomials of subgraphs. There's no obvious reason the log concavity
 would hold when you add or subtract the chromatic polynomials of graphs.<br>
In the case of Hodge theory, the objects of interest are called the "cohomology
 rings of smooth projective algebraic varieties." It's hard to overstate how
 little Hodge theory would seem to relate to graphs or matroids.

## (13.) A LONG-SOUGHT PROOF, FOUND AND ALMOST LOST by Natalie Wolchover

The GCI (Gaussian correlation inequality) links probability and geometry. The
 probability that both Gaussian random variables will simultaneously fall inside
 the rectangular region is always greater than or equal to the product of the
 individual probabilities of each variable falling in its own specified range.
 If the variables are independent, then the joint probability equals the product
 of the individual probabilities. But any correlation between the variables
 causes the joint probability to increase.

## (14.) "OUTSIDERS" CRACK 50-YEAR-OLD MATH PROBLEM by Erica Klarreich

Network sparsification has applications in data compression and efficient
 computation, but Spielman's particular problem seemed connected to the famous
 Kadison-Singer problem, a question about the foundations of quantum physics
 that had remained unsolved for almost 50 years.<br>
Other, more mathematically inclined physicists pounced on the Kadison-Singer
 problem, which they understood as a question about C*-algebras, abstract
 structures that capture the algebraic properties not just of quantum systems
 but also of the random variables used in probability theory, the blocks of
 numbers called matrices and regular numbers.
Now, using ideas from the proof of the Kadison-Singer problem, Nima Anari and
 Shayan Oveis Gharan have shown that this algorithm for finding approximate
 solutions to the asymmetric problem performs exponentially better than people
 had realized.

## (15.) MATHEMATICIANS TAME ROGUE WAVES, LIGHTING UP FUTURE OF LEDS by Kevin Hartnett

Mayboroda came up with a mathematical formula called the "landscape function"
 that predicts exactly where waves will localize and what form they'll take when
 they do. LED lights depend on the phenomenon of localization. The landscape
 function considers how the plate flexes under uniform pressure. The bulges are
 where the plate will ring, and the lines around the bulges are precisely the
 lines of localization drawn by the function.

## (16.) PENTAGON TILING PROOF SOLVES CENTURY-OLD MATH PROBLEM by Natalie Wolchover

As one journey---the classification of all convex polygon tessellations---ends,
 another is just beginning. Rao, like many tiling specialists, seeks the elusive
 "einstein," a hypothetical shape that can only tile the plane nonperiodically,
 in a pattern of tile orientations that never repeats. Researchers have already
 proved that no algorithm exists that can decide if an arbitrary collection of
 different shapes tiles the plane. Many experts suspect, though it isn't proven,
 that the single-tile decision problem is "undecidable" as well. In a backward
 kind of way, this would imply the existence of the einstein tile.

## (17.) SIMPLE SET GAME PROOF STUNS MATHEMATICIANS by Erica Klarreich

For every whole number *n*, there's a version of Set with *n* attributes and
 3<sup>*n*</sup> different cards. For each such version, we can consider
 collections of cards that contain no set---what mathematicians confusingly call
 "cap set"---and ask how large they can be. This question is one of the simplest
 problems in the mathematical field called Ramsey theory, which studies how
 large a collection of objects can grow before patterns emerge.<br>
A paper was posted online showing that the proof rules out one of the approaches
 mathematicians were using to try to create more efficient matrix multiplication
 algorithms.

## (18.) A MAGICAL ANSWER TO AN 80-YEAR-OLD PUZZLE by Erica Klarreich

In 2015, the mathematician Terence Tao presented a solution to an 80-year-old
 number theory problem posed by the ledendary Hungarian mathematician Paul
 Erdős. This particular problem, which came to be known as the Erdős discrepancy
 problem (so named because the distance from the center of the tunnel is known
 as the discrepancy), was one of his favorites, said Ben Green. "He mentioned it
 many times over the years, particularly towards the end of his life." Is there
 a list of steps that will keep you alive, no matter what sequence your captor
 chooses? To solve the problem, Tao measured the "entropy"---a concept that
 originated in coding theory---of mathematical object called multiplicative
 functions or sequences, which lie at the heart of not just the Erdős
 discrepancy problem, but also some of the deepest problems in number theory,
 such as understanding the distribution of prime numbers.<br>
Multiplicative sequences are related to deep structures in number theory. One
 example is the famous Liouville function, which, when written as a sequence,
 has a +1 or -1 in the *n*th spot depending on whether *n* has an even or odd
 number of prime factors, and which gives mathematicians a way to study the
 number of primes below a given number.

## (19.) SPHERE PACKING SOLVED IN HIGHER DIMENSIONS by Erica Klarreich

Despite the problem's seeming simplicity, it was not settled until 1998, when
 Thomas Hales finally proved Kepler's conjecture in 250 pages of mathematical
 arguments combined with mammoth computer calculations. Finding the best packing
 of equal-sized spheres in a high-dimensional space should be even more
 complicated than the three-dimensional case. Dense sphere packings are
 intimately related to the error-correcting codes used by cell phones, space
 probes and the internet to send signals through noisy channels.<br>
In dimensions eight and 24, there exist dazzlingly symmetric sphere packing
 called E<sub>8</sub> and the Leech lattice, respectively, that pack spheres
 better than the best candidates known to mathematicians in other dimensions.
 For reasons that mathematicians don't fully understand, E<sub>8</sub> and the
 Leech lattice have connections to a wide range of mathematical subjects,
 including number theory, combinatorics, hyperbolic geometry and even areas of
 physics such as string theory. They form "a nexus where lots of different areas
 of mathematics come together."<br>
Then Viazovska found the elusive auxiliary functions for E<sub>8</sub> and the
 Leech lattice, using a type of mathematical object that Ramanujan also studied
 extensively: modular forms.

# IV HOW DO THE BEST MATHEMATICAL MINDS WORK?

## (20.) A TENACIOUS EXPLORER OF ABSTRACT SURFACES by Erica Klarreich

Yet mathematicians couldn't pin down just how many simple (never intersect
 themselves) closed geodesics (straight lines) of a given length a hyperbolic
 surface can have. One concerned a formula for the volume of the so-called
 "moduli" space---the set of all possible hyperbolic structures on a given
 surface.

## (21.) A "REBEL" WITHOUT A PH.D. by Thomas Lin

When Press asked a question about the "iterated prisoner's dilemma," a variation
 of the classic game theory scenario pitting cooperation against betrayal, Dyson
 replied the next day. "It probably only took him a minute to grasp the
 solution," Press said, "and half an hour to write it out." Together, they
 published a much-cited 2012 paper in the *Proceedings of the National Academy
 of Sciences.*<br>
"I didn't invent anything new---I translated Feynman's ideas into mathematics so
 it became more accessible to the world, and, as a result, I became famous, but
 it all happened within about six months."<br>
"What I'm convinced of is that we don't understand climate, and so that's sort
 of a neutral position. I'm not saying the majority is necessarily wrong. I'm
 saying that they don't understand what they're seeing."<br>
"I'm very proud of not having a Ph.D. I think the Ph.D. system is an
 abomination. It was invented as a system for educating German professors in the
 19th century, and it works well under those conditions. It's good for a very
 small number of people who are going to spend their lives being professors. But
 it has become now a kind of union card that you have to have in order to have a
 job, whether it's being a professor or other things, and it's quite
 inappropiate for that. It forces people to waste years and years of their lives
 sort of pretending to do research for which they're not at all well suited. In
 the end, they have this piece of paper which says they're qualified, but it
 really doesn't mean anything. The Ph.D. takes far too long and discourages
 women from becoming scientists, which I consider a great tragedy. So I have
 opposed it all my life without any success at all."<br>
"People are often asking me what's going to happen next in science that's
 important, and of course, the whole point is that if it's important, it's
 something we didn't expect. All the really important things come as a big 
 surprise."<br>
"When I retired as a professor of the institute, I kept all the privileges. The
 only thing that changed is the paychecks stopped coming. I still have an office
 and all the secretarial help I need, plus a place at the lunch table. One more
 advantage is not having to go to faculty meetings."

## (22.) A BRAZILLIAN WUNDERKIND WHO CALMS CHAOS by Thomas Lin and Erica Klarreich

Even Argentina, that bitter soccer rival with a population one-fifth the size of
 Brazil's, boasts five Nobel laureates.<br>
Avila and Marcelo Viana proved a formula that predicts which side of the table a
 ball is most likely to hit next---and which side it will likely hit after a
 thousand bounces, or a million, all with the same margin of error.<br>
Two things Avila fears more than erratic buses are PowerPoint slides and income
 tax forms. "I would get fired pretty fast from most jobs," he said, adding that
 he sleeps well past noon and is "not good at managing time."<br>
For certain values of *r* larger than about 3.56995---a value called the "onset
 of chaos"---the system becomes completely unpredictable. Researchers had known
 for decades that beyond the onset of chaos, there were "islands of
 stability"---values of *r* greater than 3.56995 for which the population would
 tend, for example, to a three-year cycle or a seven-year cycle. For almost
 every other parameter beyond the onset of chaos, the equation's behavior is
 "stochastic," exhibiting the unpredictable bouncing around that is the hallmark
 of chaos.<br>
"Suppose he wants to eat chocolate. He will become a professional eater of
 chocolate."

## (23.) THE MUSICAL, MAGICAL NUMBER THEORIST by Erica Klarreich

[Zometool][zometool], Rubik's Domino<br>
Bhargava, Skinner and Zhang have also made progress toward proving the famous
 Birch and Swinnerton-Dyer conjecture, a related problem about elliptic curves
 for which the Clay Mathematics Institute has offered a million-dollar prize.
 Bhargava, Skinner and Zhang have shown that the conjecture is true for more
 than 66 percent of elliptic curves.

[zometool]: http://www.zometool.com/

## (24.) THE ORACLE OF ARITHMETIC by Erica Klarreich

Scholze's key innovation---a class of fractal structures he calls perfectoid
 spaces---is only a few years old, but it already has far-reaching ramifications
 in the field of arithmetic geometry, where number theory and geometry come
 together. Unlike many mathematicians, he often starts not with a particular
 problem he wants to solve, but with some elusive concept that he wants to
 understand for its own sake.<br>
As Scholze burrowed into the proof, he became captivated by the mathematical
 objects involved---structures called modular forms and elliptic curves that
 mysteriously unify disparate areas of number theory, algebra, geometry and
 analysis. In his mathematics classes at the University of Bonn, he never took
 notes, recalled his classmate. Scholze could understand the course material in
 real time, he said. For polynomial equations, it is fruitful to study whether
 they have solutions among alternative number system called *p*-adic numbers,
 which, like the real numbers, are built by filling in the gaps between whole
 numbers and fractions. In a *p*-adic number system, two numbers are considered
 close not if the difference between them is small, but if that difference is
 divisible many times by *p*. *P*-adic numbers are "far removed from our
 everyday intuitions," Scholze said.<br>
The perfectoid spaces make it possible to slide questions about polynomials from
 the *p*-adic world into a different mathematical universe in which arithmetic
 is much simpler. "The weirdest property about perfectoid spaces is that they
 can magically move between the two number systems," Weinstein said.<br>
Reciprocity laws are generalizations of the 200-years-old quadratic reciprocity
 law, a cornerstone of number theory and one of Scholze's personal favorite
 theorems. The law states that given two prime numbers *p* and *q*, in most
 cases *p* is a perfect square on a clock with *q* hours exactly when *q* is a
 perfect square on a clock with *p* hours. "You can interpret a lot of modern
 algebraic number theory as just attempts to generalize this law," Weinstein
 said. In the middle of the 20th century, mathematicians discovered an
 astonishing link between reciprocity laws and what seemed like an entirely
 different subject: the "hyperbolic" geometry of patterns such as M. C. Escher's
 famous angel-devil tilings of a disk. This link is a core part of the
 "Langlands program," a collection of interconnected conjectures and theorems
 about the relationship between number theory, geometry and analysis. When these
 conjectures can be proved, they are often enormously powerful: For instance,
 the proof of Fermat's Last Theorem boiled down to solving one small (but highly
 shows that the Langlands program is "deeper than we thought ... it's more
 systematic, it's ever-present."<br>
Discussing mathematics with Scholze is like consulting a "truth oracle,"
 according to Weinstein. It can be scary but also exciting for other
 mathematicians when Scholze enters their field, Bhatt said. Yet to Scholze, his
 work thus far is just a warm-up. "I'm still in the phase where I'm trying to
 learn what's there, and maybe rephrasing it in my own words," he said. "I don't
 feel like I've actually started doing research."

## (25.) AFTER PRIME PROOF, AN UNLIKELY STAR RISES by Thomas Lin

see chapter 1.

## (26.) IN NOISY EQUATIONS, ONE WHO HEARD MUSIC by Natalie Wolchover

Another compared the 180-page treatise to the *Lord of the Rings* trilogy
 because it "created a whole world." Stochastic partial differential equations
 (SPDEs) lured Hairer away from the path to a career as a physicist. Hairer's
 theory of "regularity structures" brings order to SPDEs by broadening many of
 math's most basic concepts: derivatives, expansions and even what it means to
 be a solution.<br>
His first major discovery came in 2004. Several groups were competing to prove
 that the two-dimensional stochastic Navier-Stokes equations---SPDEs that
 describe fluid flow in the presence of noise---are "ergodic," or eventually
 evolve to the same average state independent of their initial inputs. In 2011,
 he solved a famous SPDE called the Kardar-Parisi-Zhang (KPZ) equation---a model
 of interface growth, such as gthe advancing edge of a bacterial colony in a
 petri dish and the spread of water in a napkin. He was already in the thick of
 developing a more sophisticated approach for solving the KPZ equation, as well
 as even more complex SPDEs: his magnum opus, the theory of regularity
 structures. The problem with SPDEs is that they involve supremely thorny
 mathematical objects called "distributions." When a water droplet suffuses a
 napkin, the advance of the water's edge depends on the current edge, as well as
 noise. In the abstract form of an equation, the noise causes the edge to change
 infinitely quickly in space and time. And yet, according to the equation, the
 distribution that describes how quickly the edge changes in time is related to
 the square of the distribution describing how quickly it changes in space. But
 while smooth curves can easily be squared or divided, distributions do not
 submit to these arithmetic operations. He suddenly realized that he could tame
 the distributions in SPDEs using an approach modeled on the mathematical
 properties of "wavelets".

## (27.) MICHAEL ATIYAH's IMAGINATIVE STATE OF MIND by Siobhan Roberts

"The index theorem and *K*-theory are actually two sides of the same coin.
 *K*-theory is the study of flat space, and of flat space moving around."<br>
"Physicists say, "Ah, yes, but it's so small you can ignore it; we don't measure
 things that small, we do perfectly well without it." My starting point is that
 that is a mistake. I'm going back to Einstein and [Paul] Dirac and looking at
 them again with new eyes, and I think I'm seeing things that people missed. I
 believe the mathematics get simplified if you feed it in."<br>
"The most important stage is understanding. A proof by itself doesn't give you
 understanding. You can have a long proof and no idea at the end of why it
 works. But to understand why it works, you have to have a kind of gut reaction
 to the thing."

# V WHAT CAN OR CAN'T COMPUTERS DO?

## (28.) HACKER-PROOF CODE CONFIRMED by Kevin Hartnett

The technology that repelled the hackers was a style of software programming
 known as formal verification. Formally verified softwre reads like a
 mathematical proof. An entire program can be tested with the same certainty
 that mathematicians prove theorems. Advances over the past decade in so-called
 "formal methods" have inched the approach closer to mainstream practice.<br>
Appel is the lead principal investigator of a research group called DeepSpec
 that's developing formally verified computer systems. Even as the tools
 improved, another hurdle stood in the way of program verification: No one was
 sure whether it was even necessary.<br>
To start, researchers had made big advances in the technology that undergirds
 formal methods: improvements in proof-assistant programs like Coq and Isabelle
 that support formal methods; the development of new logical systems (called
 dependent-type theories) that provide a framework for computers to reason about
 code; and improvements in what's called "operational semantics"---in essence, a
 language that has the right words to express what a program is supposed to do.
 Today most formal methods researchers focus instead on verifying smaller but
 especially vulnerable or critical pieces of a system, like operating systems or
 cryptographic protocols.<br>
Over at Microsoft Research, software engineers have two ambitious formal
 verification projects under way. The first, named Everest, is to create a
 verified version of HTTPS. The second is to create verified specifications for
 complex cyber-physical systems such as drones. Where typical software follows
 discrete, unambiguous steps, the programs that tell a drone how to move use
 machine learning to make probabilistic decisions based on a continuous stream
 of environmental data. It's far from obvious how to reason about that kind of
 uncertainty or pin it down in a formal specification.

## (29.) WILL COMPUTERS REDEFINE THE ROOTS OF MATH? by Kevin Hartnett

Set theory has sufficed as a foudation for more than a century, but it can't
 readily be translated into a form that computers can use to check proofs. So
 with his decision to start formalizing mathematics on the computer, Voevodsky
 set in motion a process of discovery that ultimately led to something far more
 ambitious: a recasting of the underpinnings of mathematics.<br>
An advantage of set theory as a foundational system is that it is very
 economical---every object mathematicians could possibly want to use is
 ultimately built from the null set. On the other hand, it can be tedious to
 encode complicated mathematical objects as elaborate hierarchies of sets. This
 limitation becomes problematic when mathematicians want to think about objects
 that are equivalent or isomorphic in some sense, if not necessarily equal in
 all respects. For example, the fraction 1/2 and the decimal 0.5 represent the
 same real number but are encoded very differently in terms of sets. But set
 theory isn't only way to do mathematics. The proof assistant programs Coq and
 Agda, for example, are based on a different formal system called type
 theory.<br>
Type theory has its origins in an attempt to fix a critical flaw in early
 versions of set theory. Russell defined a new set: the set of all sets that do
 not contain themselves. He asked whether that set contains itself, and he
 showed that answering that question produces a paradox. Russell created type
 theory as a way out of this paradox. If a collection does contain other
 collections, it is no longer allowed to be a *SET*, but is instead something
 that can be thought of as a *MEGASET*---a new kind of type defined specifically
 as a collection of objects with themselves are collections of objects. One can
 imagine, say, a type called a *SUPERMEGASET* that collects only objects that
 are *MEGASETS*.<br>
An important distinction between set theory and type theory lies in the way
 theorems are treated. In set theory, a theorem is not itself a set---it's a
 statement about sets. By contrast, in some versions of type theory, theorems
 and *SETS* are on equal footing. They are "types"---a new kind of mathematical
 object. A theorem is the type whose elements are all the different ways the
 theorem can be proved. There are often good reasons in mathematics to keep
 track of the various ways in which two objects are equivalent, and type theory
 does this automatically by bundling equivalences together into a single
 type.<br>
One way topologists do this with the notion of homotopy, which provides a useful
 definition of equvalence: Spaces are homotpopy equivalent if, roughly speaking,
 one can be deformed into the other by shrinking or thickening regions, without
 tearing. A topologist might think of two points in a space as equivalent
 whenever there is a path connecting them. Then the collection of all paths
 between points *x* and *y* can itself be viewed as a single type, which
 represents all proofs of the theorem *x*=*y*. Paths between paths can be
 thought of as higher-order relationships between points in a space.<br>
Infinity-groupoids encode all the points in a space, including paths of paths,
 and paths of paths of paths. Yet Voevodsky was able to create an interpretation
 of type theory in the language of infinity-groupoids, an advance that allows
 mathematicians to reason efficiently about infinity-groupoids without ever
 having to think of them in terms of sets. This advance ultimately led to the
 development of univalent foundations.<br>
In 1972 the Swedish logician Per Martin-Löf introduced his own version of type
 theory inspired by ideas from Automath, a formal language for checking proofs
 on the computer. Martin-Löf type theory (MLTT) was eagerly adopted by computer
 scientists, who have used it as the basis for proof-assistant programs. In the
 mid-1990s, MLTT intersected with pure mathematics when Michael Makkai realized
 it might be used to formalize categorical and higher-categorical mathematics.
 Voevodsky followed Makkai's path but used groupoids instead of categories. This
 allowed him to create deep connnections between homotopy theory and type
 theory.

## (30.) LANDMARK ALGORITHM BREAKS 30-YEAR IMPASSE by Erica Klarreich

In November 2015, a theoretical computer scientist presented an algorithm that
 was hailed as a breakthrough in mapping the obscure terrain of complexity
 theory, which explores how hard computational problems are to solve. László
 Babai announced that he had come up with a new algorithm for the "graph
 isomorphism" problem, one of the most tantalizing mysteries in computer
 science. For decades, the graph isomorphism problem has held a special status
 within complexity theory. It seems easier than the hard problems, but harder
 than the easy problems. It is one of the two most famous problems in this
 strange gray area. (The only other such problem is the problem of factoring a
 number into primes.) The graph isomorphism question simply asks when two graphs
 are really the same graph in disguise because there's a one-to-one
 correspondence (an "isomorphism") between their nodes that preserves the ways
 the nodes are connected.<br>
It's possible, in theory, for an all-knowing being to convince an ordinary
 person that two graphs are different without giving away any hints about where 
 the differences lie. No one has ever found a blind-taste-test protocol for any
 NP-complete problem. For that and other reasons, there's a fairly strong
 consensus among theoretical computer scientists that graph isomorphism is
 probably not NP-comeplete. For the reverse question---whether graph isomorphism
 is in P---the evidence is more mixed. On the one hand, there are practical
 algorithms for graph isomorphism that can't solve the problem efficiently for
 every single graph, but that do well on almost any graph you might throw at
 them, even randomly chosen ones. On the other hand, graph isomorphism is what
 computer scientists call a "universal" problem: Every possible problem about
 whether two "combinatorial structures" are isomorphic can be recast as a graph
 isomorphism problem. "Usually when you have that kind of universality, it
 implies some kind of hardness," Grochow said.<br>
Even though the new algorithm has moved graph isomorphism much closer to P than
 ever before, Babai speculated in his first talk that the problem may lie just
 outside its borders. That would be the most interesting possibility, said Luca
 Trevisan, since it would make graph isomorphism the first natural problem to
 have a quasi-polynomial algorithm but no polynomial algorithm. "It would show
 that the landscape of complexity theory is much richer than we thought," he
 said. If this is indeed the case, however, don't expect a proof anytime soon:
 Proving it would amount to solving the P versus NP problem, since it would mean
 that graph isomorphism separates the problems in P from the NP-complete
 problems. Many computer scientists believe, instead, that graph isomorphism is
 now on a glide path that will eventually send it coasting into P. That is the
 usual trajectory, Trevisan said, once a quasi-polynomial algorithm has been
 found.

## (31.) A GRAND VISION FOR THE IMPOSSIBLE by Thomas Lin and Erica Klarreich

In 1992, a team of computer scientists astonished their colleagues by proving a
 result called the PCP theorem, which enabled researchers to show that for a
 wide variety of computational problems, even finding good approximate solutions
 is NP-hard, meaning that it's a task that, most computer scientists believe, is
 impossible to carry out efficiently. It opened up a new line of inquiry: trying
 to generate "exact hardness" results, statements of the form, "Here's an
 approximation algorithm for problem X and a proof that finding any better
 approximation algorithm is NP-hard."<br>
One of Khot's problems got much simpler if he made a certain assumption about
 how difficult a certain approximation problem is. He eventually named this
 assumption the Unique Games Conjecture. The first hint of the conjecture's
 power came a year later when Khot and Oded Regev showed that if the conjecture
 is true, then it is possible to establish the exact approximation hardness of a
 problem about networks called Minimum Vertex Cover. Then, in 2004, Khot and
 three collaborators showed that if the conjecture is true, then the best known
 approximation algorithm for another network problem called Max Cut---an
 algorithm that many computer scientists had assumed was just a placeholder
 until they could find a better one---was truly the best possible. In 2008, Prasad Raghavendra showed that if the UGC is true, then it's possible to establish the approximation hardness of an entire category of common computational problems called "constraint satisfaction" problems.

# VI WHAT IS INFINITY?

## (32.) TO SETTLE INFINITY DISPUTE, A NEW LAW OF LOGIC by Natalie Wolchover

In the course of exploring their universe, mathematicians have occasionally
 stumbled across holes: statements that can be neither proved nor refuted with
 the nine axioms, collectively called "ZFC," (Zermelo-Fraenkel set theory with
 the axiom of choice) that serve as the fundamental laws of mathematics. Chief
 among the holes is the continuum hypothesis, a 140-year-old statement about the
 possible sizes of infinity. The continuum hypothesis asserts that there is no
 infinity between the smallest kind---the set of counting numbers---and what it
 asserts is the second-smallest---the continuum. It "must be either true or
 false," the mathematical logician Kurt Gödel wrote in 1947, "and its
 undecidability from the axioms as known today can only mean that these axioms
 do not contain a complete description of reality."<br>
"If forcing axioms are right, then the continuum hypothesis is false," Koellner
 said. "And if the inner-model axiom ("V = ultimate L.") is right, then the
 continuum hypothesis is true." According to the researchers, choosing between
 the candidates boils down to a question about the purpose of logical axioms
 and the nature of mathematics itself. Are axioms supposed to be the grains of
 truth that yield the most pristine mathematical universe? In that case,
 V=ultimate L may be most promising. Or is the point to find the most fruitful
 seeds of mathematical discovery, a criterion that seems to favor forcing
 axioms? According to some theorists, there are myriad mathematical universes,
 some in which the continuum hypothesis is true and others in which it is
 false---but all equally worth exploring. Meanwhile, "there are some skeptics,"
 Koellner said, "people who for philosophical reasons think set theory and the
 higher infinite doesn't even make any sense." To set theory skeptics like the
 late Solomon Feferman this didn't matter. "They're simply not relevant to
 everyday mathematics," Feferman said in 2013.<br>
Cantor couldn't prove this "continuum hypothesis" using the axioms of set
 theory. Nor could anyone else.<br>
In 1931, with a pair of proofs, the 25-year-old Gödel showed that a specifiable
 yet sufficiently complex axiomatic system like ZFC could never be both
 consistent and complete. Proving that its axioms are consistent (that is, that
 they don't lead to contradictions) requires an additional axiom not on the
 list. And to prove that ZFC-plus-that-axiom is consistent, yet another axiom is
 needed. Gödel himself proved that the truth of the continuum hypothesis is
 consistent with ZFC, and Paul Cohen proved the opposite, that the negation of
 the hypothesis is also consistent with ZFC. Their combined results demonstrated
 that the continuum hypothesis is actually independent of the axioms. Something
 beyond ZFC is needed to prove or refute it.<br>
Gödel conceived of a small and constructible model universe called "L,"
 populated by starting with the empty set and iterating it to build bigger and
 bigger sets. This makes the axiom "V=L," or the statement that the universe of
 sets V is equal to the "inner model" L, appealing. L is too small to encompass
 "large cardinals," infinite sets that ascend in a never-ending hierarchy, with
 levels named "inaccessible," "measurable," "Woodin," "supercompact," "huge" and
 so on, altogether composing a cacophonous symphony of infinities. Discovered
 periodically over the 20th century, these large cardinals cannot be proved to
 exist with ZFC and instead must be posited with additional "large cardinal
 axioms." Although it has not yet been constructed, ultimate L is the name for
 the hypothetical inner model that includes supercompacts and therefore all
 large cardinals. The axiom V=ultimate L asserts that this inner model is the
 universe of sets.

## (33.) MATHEMATICIANS BRIDGE FINITE-INFINITE DIVIDE by Natalie Wolchover

The finite-infinite divide separates two kinds of mathematical statements:
 "finitistic" ones, which can be proved without invoking the concept of
 infinity, and "infinistic" ones, which rest on the assumption that infinite
 objects exist. Mapping and understanding this division is "at the heart of
 mathematical logic," said Theodore Slaman. This endeavor leads directly to
 questions of mathematical objectivity, the meaning of infinity and the
 relationship between mathematics and physical reality.<br>
More concretely, the proof settles a question that has eluded top experts for
 two decades: the classification of a statement known as "Ramsey's theorem for
 pairs," or *RT*<sub>2</sub><sup>2</sup>. Where almost all theorems can be shown
 to be equivalent to one of a handful of major systems of logic---sets of
 starting assumptions that may or may not include infinity, and which span the
 finite-infinite divide---*RT*<sub>2</sub><sup>2</sup> falls between these
 lines. You color each pair of objects either red or blue according to some
 rule. When this is done, *RT*<sub>2</sub><sup>2</sup> states that there will
 exist an infinite monochromatic subset: a set consisting of infinitely many
 numbers, such that all the pairs they make with all other numbers are the same
 color. The colorable, divisible infinite set in *RT*<sub>2</sub><sup>2</sup>
 are abstractions that have no analogue in the real world. And yet, Yokoyama and
 Patey's proof shows that mathematicians are free to use this infinite apparatus
 to prove statements in finitistic mathematics---including the rules of numbers
 and arithmetic, which arguably underlie all the math that is required in
 science---without fear that the resulting theorems rest upon the logically
 shaky notion of infinity.<br>
Set theory yielded proofs of theorems that were hard to swallow, such as the
 1924 Banach-Tarski paradox, which says that if you break a sphere into pieces,
 each composed of an infinitely dense scattering of points, you can put the
 pieces together in a different way to create two spheres that are the same size
 as the original. Hilbert and his comtemporaries worried: Was infinitistic
 mathematics consistent? Was it true? He hoped to stay in Cantor's paradise and
 obtain proof that it stood on stable logical ground. Hilbert tasked
 mathematicians with proving that set theory and all of infinitistic mathematics
 is finitistically reducible, and therefore trustworthy. In a shocking result,
 Gödel proved that no system of logical axioms (or starting assumptions) can
 ever prove its own consistency; to prove that a system of logic is consistent,
 you always need another axiom outside of the system.<br>
Can Wiles' 150-page, infinity-riddled proof be trusted? Simpson estimates that
 some 85 percent of known mathematical theorems can be reduced to finitistic
 systems of logic.<br>
*RT*<sub>2</sub><sup>2</sup> has numerous finitistic consequences, statements
 about natural numbers that are now known to be expressible in primitive
 recursive arithmetic, and which are thus certain to be logically consistent.
 Moreover, these statements---which can often be cast in the form "for every
 number *X*, there exists another number *Y* such that..."---are now guaranteed
 to have primitive recursive algorithms associated with them for computing *Y*.

## (34.) MATHEMATICIANS MEASURE INFINITES AND FIND THEY'RE EQUAL by Kevin Hartnett

In 1900, the German mathematician David Hilbert made a list of 23 of the most
 important problems in mathematics. He put the continuum hypothesis at the
 top.<br>
In the 1960s, Cohen developed a method called "forcing" that demonstrated that
 the continuum hypothesis is independent of the axioms of mathematics---that is,
 it couldn't be proved within the framework of set theory. (Cohen's work
 complemented work by Kurt Gödel in 1940 that showed that the continuum
 hypothesis couldn't be disproved within the usual axioms of mathematics.)<br>
For a model theorist, a "theory" is the set of axioms, or rules, that define an
 areq of mathematics. You can think of model theory as a way to classify
 mathematical theories. In 1967, Keisler introduced what's now called Keisler's
 order, which seeks to classify mathematical theories on the basis of their
 complexity.<br>
One of Malliaris' and Shelah's goals was to identify more of the properties that
 make a theory maximally complex according to Keisler's criterion. As their work
 progressed, they realized that this question was parallel to the question of
 whether p and t are equal. They proved that the two properties are equally
 complex (they both cause maximal complexity), and they proved that p equals t.
 Malliaris and Shelah proved that p and t are equal by cutting a path between
 model theory and set theory that is already opening new frontiers of research
 in both fields.

# VII IS MATHEMATICS GOOD FOR YOU?

## (35.) A LIFE INSPIRED BY AN UNEXPECTED GENIUS by John Pavlus

In 2014, Ono and his collaborators Michael Griffin and Ole Warnaar published a
 breakthrough result in algebraic number theory that generalized one of
 Ramanujan's own results. Ono's work, which is based on a pair of equations
 called the Rogers-Ramanujan identities, can be used to easily produce algebraic
 numbers (such as phi, better known as the "golden ratio").<br>
In one of his published manuscripts, Ramanujan recorded a lot of
 elementary-looking results called congruences. In the 1960s Jean-Pierre Serre,
 himself, a Fields medalist, revisited some of these results, and in them he
 found glimpses of a theory that he named the the theory of Galois
 representations. This theory of Galois representations is the language that
 Andrew Wiles used in the 1990s to prove Fermat's last theorem.

## (36.) TO LIVE YOUR BEST LIFE, DO MATHEMATICS by Kevin Hartnett

## (37.) WHY MATH IS THE BEST WAY TO MAKE SENSE OF THE WORLD by Ariel Bleicher

We use neat mathmetical objects to think about symmetries, called groups. This
 is useful because if you're trying to solve equations, and you know you have
 symmetries, you can essentially find a way mathematically to get rid of those
 symmetries and make your equations simpler.

