# [알고리즘, 인생을 계산하다][homepage], 브라이언 크리스천, 톰 그리피스 저, 이한음 역, 청림출판 (2018)

[원서][english_edition]

[homepage]: http://www.chungrim.com/booktotal/bin/view.php?&code=book&isbn=978-89-352-1205-7&cpage=1
[brian_christian]: https://brianchristian.org/
[tom_griffiths]: http://cocosci.berkeley.edu/tom/index.php
[english_edition]: http://algorithmstoliveby.com/

## 제1장 살펴보는 일을 멈춰야 할 때 _ 최적 멈춤

[Thomas S. Ferguson][ferguson], "Optimal Stopping and Applications" (최적 멈춤을
 수학적으로 자세히 설명),
 ["Who Solved the Secretary Problem?"][who_solved_the_secretary_problem]
 ([비서 문제][secretary_problem]의 기원과 본질)<br>
메릴 플러드(Merrill Flood)는 수학계 바깥에는 거의 알려지지 않았지만,
 컴퓨터과학에 지대한 영향을 미친 인물이다. 그는 순회 외판원 문제를 널리 알리고,
 죄수의 딜레마를 고안했으며, '소프트웨어'라는 용어도 창안했을 가능성이 있다.<br>
비서 문제는 거의 완벽한 수학 퍼즐임이 입증되었다. 즉 간단하게 설명할 수 있지만,
 풀기는 지독하게 어렵고, 답은 아주 간결한 반면, 흥미로운 의미를 함축하고 있다는
 점에서 그렇다. 그 때문에 이 문제는 1950년대에 입에서 입으로 들불처럼 수학계
 전체로 퍼졌고, 1960년 가드너의 수학 칼럼 덕분에 일반 대중의 상상까지 사로잡게
 되었다. 이 문제와 변형한 문제들을 분석한 논문들이 너무나 많이 쏟아져나왔기에,
 1980년대 무렵에는 아예 별도의 하위 분야가 생겼을 정도다.<br>
가능한 최상의 전략인 37% 법칙을 따를 때의 실패율이 63%라는 사실은 정신을 번쩍
 들게 만든다. 최적 멈춤 전략은 건초 더미가 아무리 커도 그것에 대처하는 최고의
 방어 전략이 된다.<br>
완전 정보 게임은 예기치 않은 다소 기이한 결론으로 이어진다. 정략 결혼이 사랑
 탐색보다 성공할 가능성이 더 높다는 것이다.<br>
Rogerson, Shimer, amd Wright,
 ["Search-Theoretic Models of the Labor Market: A Survey"][search_theoretic_models_of_the_labor_market]
 (구직 맥락에서의 최적 멈춤 문제 개괄)<br>
Donald Shoup, ["The High Cost of Free Parking"][high_cost_of_free_parking]<br>
강도가 해야 할 강도질 횟수는 달아날 확률을 잡힐 확률로 나눈 값과 거의 같다.<br>
최적 멈춤 모형에서는 대개 고려하지 않는 탐색의 '내생적' 시간 비용이야말로 사람의
 실제 의사 결정과 모형이 내놓는 값이 달라지는 이유를 설명해줄 수도 있다.
 그렇다고 최적 멈춤 문제가 덜 중요하다는 말은 아니다. 실제로는 그 때문에 더욱
 중요해진다. 시간의 흐름이 모든 의사 결정 문제를 최적 멈춤 문제로 바꾸기
 때문이다.

[ferguson]: https://www.math.ucla.edu/~tom/
[who_solved_the_secretary_problem]: https://www.math.upenn.edu/~ted/210F10/References/Secretary.pdf
[secretary_problem]: https://en.wikipedia.org/wiki/Secretary_problem
[search_theoretic_models_of_the_labor_market]: http://home.uchicago.edu/shimer/wp/search-survey.pdf
[high_cost_of_free_parking]: https://www.routledge.com/The-High-Cost-of-Free-Parking-Updated-Edition/Shoup/p/book/9781932364965

## 제2장 가장 최신의 것 vs 가장 좋은 것 _ 탐색/이용

우리가 나이를 먹을수록 목표를 어떻게 바꾸어야 할지, 최상의 것을 선택하려는
 시도가 반드시 가장 합리적인 행동 경로라고 할 수 없는 이유를 이해할 근본적인
 통찰력도 제공한다.<br>
그것은 우리가 아직 논의하지 않은 요소에 전적으로 의존한다. 카지노에서 얼마나
 오래 머물 계획인가 하는 것이다.<br>
기틴스 지수(Gittins index)는 보상이 기하급수적으로 할인되는 다중 슬롯머신 문제를 완전히 해결한다. 0-9이라는 기록은 그댓값이 0.5000이지만, 기틴스 지수는
 0.7029다. 다시 말해, 10번 당기면 7번 이긴다는 것을 알고 있는 기계보다 전혀
 당겨보지 않은 기계가 더 낫다는 뜻이다! 그 칸에서부터 대각선을 따라 내려가면,
 지수는 궁극적으로 0.5000ㅇ로 수렴된다. 사실 처음 당겼을 때 져서 승패 기록이
 0-1일 때에도 기틴스 지수는 여전히 50%를 넘는다는 점을 주목하자. 따라서 탐색을
 통해 배운 것의 결과를 이용할 기회가 있기만 하다면, 기틴스 지수는 미지의 것을
 선호하는 태도에 공식적이면서 엄정한 정당성을 제공한다.<br>
언제나 실패하는 횟수가 최소인 대안을 선택하는 최소 실패 법칙(Least Failures
 Rule) 전략이다. 이 전략은 이기면 그대로 원리를 토대로 하며, 당신이 내일의
 보상에 본질적으로 오늘의 보상만큼 가치를 두는 신중한 성격이라면 기틴스 지수와
 똑같은 결과가 나온다. 여러 새로운 식당이 계속 문을 여는 대도시에서의 최소 실패
 방침은 어떤 식당에 갔는데 실패한다면, 다른 식당들이 아주 많으므로 두 번 다시
 가지 말라는 것이 된다.<br>
가능한 최소 후회는 손잡이를 잡아당길 때마다 로그적으로 증가하는 후회다. 발견한
 것 중에서 가장 인기 있는 것은 신뢰 상한(Upper Confidence Bound) 알고리즘이라고
 한다. 상한 알고리즘이 제시한 권고안들은 기틴스 지수가 제시한 것들과
 비슷하겠지만, 계산하기가 훨씬 더 쉽고, 기하급수적 할인이라는 가정을 요구하지도
 않는다.<br>
장기적으로 낙관론은 최고의 후회 예방법이다.<br>
아마존과 구글 같은 거대 기술 기업들은 2000년경부터 이용자들을 대상으로 실시간
 A/B 검사를 시작했다.<br>
각 팔의 보상 확률이 시간이 흐르면서 변한다면---쉬지 않는 슬롯머신(restless
 bandit)이라는 이름이 붙어 있다---문제는 훨씬 더 어려워진다. 사실 너무나
 어려워서, 문제를 완전히 해결할 만한 적당한 알고리즘이 아예 없다. 아마 앞으로도
 등장하지 않을 것이라고 믿어진다. 인간의 과잉 탐색이 세계가 쉴 새 없이 변한다고
 가정한 결과라는 개념을 뒷받침하는 최근 연구 자료를 제시한다.<br>
아이의 목표가 탐색이라고 한다면, 아이가 해야 할 일이 바로 그런 것들이다.<br>
노년이 이용의 시간임을 인정하면, 노화의 고전적인 현상 중 일부를 새로운 관점에서
 바라보는 데 도움이 된다. 예를 들어, 대학(만난 적이 없는 사람들이 가득한 새로운
 사회 환경)에 들어가는 것은 대개 긍정적이고 흥분되는 시간이지만,
 요양소(마찬가지로 만난 적이 없는 사람들이 가득한 새로운 사회 환경)에 들어가는
 것은 고역스러울 수 있다.

## 제3장 질서를 찾다 _ 정렬하기

컴퓨터과학에서 비둘기집 원리는 알고리즘의 이론적 특성에 관한 기본 사실들을
 정립하는 데 쓰인다. 예를 들어, 정보 손실 없이 가능한 파일을 압축하는 알고리즘을
 짜기란 불가능하다. 짧은 파일보다 긴 파일이 더 많이 있기 때문이다.<br>
선형 시간 정렬은 제자리에 꽂아야 할 책이 얼마나 많은지와 상관없이, 각 책을 상수
 시간에 다룬다는 의미다.<br>
Jyrki Katajainen and Jesper Larsson Träff, "A meticulous analysis of mergesort
 programs"<br>
[Sort Benchmark Home Page][sort_benchmark]<br>
항목 *n*개의 집합을 정렬하는 방법은 정확히 *n*!가지가 있으므로, 한 정렬은 정확히 log*n*! 비트의 정보를 생산한다. 이 값은 근사적으로 *n*log*n* 비트에 해당한다.
 *n*!<*n*<sup>*n*</sup>이고, log*n*!<log*n*<sup>*n*</sup>이므로,
 log*n*!<*n*log*n*이 되다. 이렇게 log*n*! 대신 근삿값인 *n*log*n*을 취하는 것을
 스털링 근사(Stirling's approximation)라고 한다. 두 항목을 짝지어서 한 차례
 비교하면 기껏해야 1비트의 정보가 나오므로, *n*가지 항목의 가능한 *n*!가지 정렬
 중에서 맞는 것에 도달하기까지 불확실성을 완전히 해소하려면 *n*log*n*번 비교를
 해야 한다.<br>
완벽하게 정렬할 필요가 없을 때도 있기 때문이다. 그리고 때로는 일대일로 비교하지
 않고서도 정렬을 할 수 있다. 이 두 원리를 조합하면, 현실적으로 선형로그 시간보다
 더 빨리 대강 분류할 수 있다. 버킷 정렬(Bucket Sort)이라는 알고리즘은 그 점을
 멋지게 보여준다. *n*개의 항목을 *m*개의 버킷으로 분류하고 싶다면, 그 분류를
 *O*(*nm*) 시간에 할 수 있다는 것이다. 그리고 버킷의 수가 항목의 수에 비해 작은
 한, 빅오 개념에 따라 그 시간은 *O*(*n*), 즉 선형 시간으로 다루어질 것이다.<br>
실제로 선형로그 장벽을 깨는 역할을 하는 요소는 정렬하는 항목들로부터 이끌어내는
 분포라고 알려지고 있다. 버킷을 잘 고르면, 항목들이 크기가 거의 균등한 집단들로
 나뉠 것이다. 정렬이 근본적으로 규모 피해(scale hurt) 특성을 지닌다는 점을
 생각하면, 이는 완벽한 정렬을 향한 커다란 진전이라고 할 수 있다.<br>
축구에서 3:2라는 점수는, 이긴 팀이 실제로 실력이 더 나은 팀을 확률이 8분의 5에
 불과하다는 의미다. 설령 6:1로 압승하더라도 그것이 통계적 우연일 확률이 7%나
 된다. 잡음이 있는 비교기(noisy comparator)를 일단 허용하면, 일부
 컴퓨터과학자들이 가장 신성시하는 알고리즘들은 쓰레기통에 처박히게 된다.
 애클리는 알고리즘에서도 강건성(robustness)의 미덕을 인정하기 시작할 때가
 되었다고 주장한다. 합병 정렬은 몹시 효율적이라는 점 때문에 취약할 수 있다. 사실
 잡음이 있는 비교기 앞에서 최고의 알고리즘은 거품 정렬이 아니다. 이 특별한
 영예는 비교 계수 정렬(Comparison Counting Sort)이라는 알고리즘에게 돌아간다. 이
 알고리즘은 각 항목을 다른 모든 항목들과 비교하여 그 항목보다 더 큰 항목들이
 얼마나 많은지 집계를 낸다. 그러면 이 수를 해당 항목의 순위를 비교하는 데 직접
 쓸 수 있다.<br>
싸움 (회피 행동, displacement; 쪼는 순서, pecking order; 순위제 dominance
 hierarchy) 대신에 경주 (단 한 번의 경기, 기수에서 서수로의 도약)

[sort_benchmark]: http://sortbenchmark.org/

## 제4장 잊어라 _ 캐싱

"어떤 이들은 어떤 문제를 접하면 이렇게 생각한다. '아는 거야, 정규 표현을
 써야지.' 이제 그들은 두 가지 문제를 지니게 된다." (넷스케이프 공학자 제이미
 자윈스키가 유즈넷에 올린 농담)<br>
최적 정책을 미리 내다보고 실행할 가상의 전지전능한 알고리즘은 오늘날 벨라디를
 기리는 차원에서 벨라디 알고리즘(Bélády's Algorithm)이라고 불린다. 벨라디
 알고리즘은 컴퓨터과학자들이 천리안 알고리즘(Algorithm clairvoyant)이라고 말하는
 것의 한 예다. 미래의 데이터를 통해 정보를 얻는 알고리즘이다.<br>
혁신적인 캐싱 전략이 많이 있으며, 그중에는 조건이 맞으면 LRU를 능가할 수 있는
 것들도 있긴 하지만, 컴퓨터과학자들은 압도적이라 할만큼 LRU 자체---그리고 그
 방법을 약간 수정한 것들 (이들은 모두 캐시 관리 성능 검사에서 LRU보다 뛰어나다는
 것이 드러났다)---를 선호하며, 그것들은 다양한 규모로 매우 여러 가지 응용
 프로그램에 구현되어있다.<br>
Daniel D. Sleator and Robert E. Tarjan, "Amortized Efficiency of List Update and
 Paging Rules" (1985). LRU 원리---뽑은 항목을 언제나 단순히 목록의 맨 앞에 돌려
 놓는---를 따른다면, 검색에 걸리는 총 시간은 미래를 알고 있다고 할 때 걸리는
 시간의 2배를 결코 초과하지 못할 것이다.<br>
방금 쓰인 단어가 직후에 다시 출현할 가능성이 가장 높고, 그렇지 않은 단어는
 시간이 흐를수록 다시 나타날 확률이 줄어든다는 것을 발견했다. 다시 말해, 현실
 자체가 에빙하우스 곡선을 모방한 통계를 지닌다.<br>
기억 용량이 더 클수록, 원하는 정보를 검색하여 인출하는 시간이 더 길어지는 것은
 피할 수 없어요.<br>
우리가 '인지력 저하(cognitive decline)'라고 부르는 것---지연과 검색 오류---이
 검색 과정이 느려지거나 저하되는 것이 아니라, (적어도 어느 정도는) 우리가 훑어야 하는 정보의 양이 점점 더 늘어남에 따른 불가피한 결과일 수도 있다고 주장했다.

## 제5장 중요한 것부터 하라 _ 일정 계획

"살아 있는 개구리를 먹는 것으로 아침을 시작한다면, 하루 내내 그보다 나쁜 일은
 일어나지 않을 것이다."<br>
1874년 부유한 변호사의 아들인 프레더릭 테일러(Fredrick Taylor)는 하버드대학교의
 입학 허가를 받았지만 포기하고서, 펌프 회사에 수습 기계공으로 들어갔다. 처음에는 선반공으로 일하다가 승진을 거듭한 끝에 공장장을 거쳐서 이윽고 수석 기술자가
 되었다. 그 과정에서 그는 자신이 감독하는 기계(그리고 사람)가 시간을 그다지
 효율적으로 쓰지 못하고 있다는 확신을 갖게 된다. 그리하여 그는 과학적
 관리(Scientific Management)라는 분야를 개철하게 되었다. 기획실 한가운데에
 모두가 볼 수 있도록 공장의 일정표를 적은 게시판이 있었다. 게시판에는 공장의
 모든 기계가 표시되어 있고, 어떤 기계가 지금 어떤 일을 하고 있으며, 어떤 일들이
 대기 중인지가 다 적혀 있었다. 이 방식은 테일러의 동료인 헨리 갠트(Henry
 Gantt)의 견해를 토대로 나온 듯하며, 1910년에 갠트가 개발한 '갠트 도표'는 미국의
 후버 댐에서 주간 고속도로 망에 이르기까지 20세기의 가장 야심적인 건설 계획들 중
 상당수를 체계화하는 데 기여했다.<br>
우리는 대개 '지체'를 게으름이나 회피 행동과 연관 짓지만, 일들을 가능한 한 빨리
 다 끝내기 위해 열심히 열정적으로 노력하는 사람에게서도 쉽게 나타날 수 있다.
 여러 가지 사소한 과제들에 주의를 돌림으로써 주요 과제를 미루는 것도 '하위
 목표를 완수하기 위해 서두르는' 것으로 비칠 수 있다.<br>
그들이 태양계를 가로질러 보낸 해결책은 무엇이었을까? 우선순위 상속(priority
 inheritance)이었다. 우선순위가 낮은 과제가 우선순위가 높은 자원을 차단하는 일이
 발생하면, 그 순간에 우선순위가 낮은 과제가 자신이 차단하고 있는 과제의
 우선순위를 '상속함으로써' 일시적으로 우선순위가 가장 높은 과제로 바뀌게 하는
 것이다.<br>
이것은 선행 제약이 우선순위 역전을 일으킨 교과서적인 사례였다.<br>
[Complexity results for scheduling problems][complexity_results_for_scheduling_problems]
 대다수의 일정 관리 문제들은 쉬운 해결책이 결코 없음을 시인한다. 자신의 일정표를
 완벽하게 관리하려고 노력하는 것이 힘들다고 느껴진다면, 아마 실제로 그렇기
 때문일 것이다.<br>
매번 새로운 일거리가 맡겨질 때마다, 그 일의 중요도를 완수하는 데 걸릴 시간으로
 나누라는 것이다. 지금 하고 있는 과제보다 그 값이 더 높다면, 새 일로 전환하라.
 일정 계획 이론이 만능열쇠나 스위스 군용 칼이 되고자 할 때, 즉 어느 한
 문제에만이 아니라 많은 문제들에 적용되는 최적 전략이 되고자 할 때 필요한 것에
 가장 가까운 것이 바로 이 알고리즘이다.<br>
스래싱(thrashing) 상태에서는 본질적으로 일에 진척이 전혀 없으므로, 일을 전혀 안
 하는 것보다 잘못된 순서로라도 일을 하는 쪽이 더 낫다. 2001년 2.4판으로 시작한
 리눅스에 쓰인 '*O*(*n*) 스케줄러'는 모든 처리 과정을 우선순위에 따라
 정렬했기에, 처리 과정이 늘어날수록 시간이 더 오래 걸렸다. 2003년 리눅스
 2.6에서는 '*O*(1) 스케줄러'를 채택하여 이 문제를 해소했다. 처리 과정이 얼마나
 많든지 상관없이, 미리 정한 수의 버킷들에 모든 처리 과정들을 할당하여 버킷
 정렬하는 방식이었다. 하지만 이 버킷 정렬 방식은 복잡한 발견법을 사용해야
 하기에, 2007년의 리눅스 2.6.23판부터는 '*O*(1) 스케줄러'를 더 직관적으로 와
 닿는 '완벽하게 공정한 스케줄러(Completely Fair Scheduler, CFS)'로 바꾸었다.
 리눅스에서는 최소 이용 조각이 약 3/4밀리초임이 밝혀졌고,
 "sysctl_sched_min_granularity" 변수에 따라 정해진다.<br>
잡다한 짧은 작업들을 처리하느라 문맥 전환을 많이 하고 있다면, 컴퓨터과학에서
 나온 또 다른 개념을 활용할 수 있다. 바로 인터럽트 병합(interrupt
 coalescing)이다. 리눅스는 2007년부터 타이머 병합을 지원하기 시작했다.
 마이크로소프트는 2009년 윈도우 7부터 윈도우에 그 기능을 포함시켰다. 애플도
 2013년 OS X 메버릭스에 추가했다. 학교에서는 교수실의 개방 시간을 정하는 것이
 학생들로부터의 방해를 병합하는 한 방법이다. 어떤 단점이 있든 간에, 정해진
 시간에 열리는 주례 회의는 자연스럽게 생기는 방해와 계획에 없는 문맥 전환을 막는
 최선의 방어 수단 중 하나다. 커누스는 1990년 이래로 전자우편 주소를 가진 적이
 없다.

[complexity_results_for_scheduling_problems]: http://www2.informatik.uni-osnabrueck.de/knust/class/

## 제6장 미래 예측 _ 베이즈 규칙

베이즈가 강력하게 옹호하고 나섰던, 한때 논란이 분분했던 수학인 미적분을 써서
 라플라스는 확률들이 이 방대한 스펙트럼을 하나의 추정값으로 요약할 수 있음을,
 그리고 그 일이 경이로울 만큼 쉽다는 것을 입증할 수 있었다. 사실 *n*번 뽑아서
 당첨 복권이 w장 나온다고 할 때, 기댓값은 그저 당첨 복권의 수에 1을 더한 값을
 시도한 횟수에 2를 더한 값으로 나누면 된다. 확률을 추정하는 이 믿어지지 않을
 만큼 단순한 체계를 라플라스 법칙(Laplace's Law)이라고 하며, 사건의 역사를
 토대로 사건의 확률을 추정해야 하는 모든 상황에 쉽게 적용된다.<br>
이 관계를 기술하는 수학 공식은 얄궂게도 실제로 그 일에 큰 발전을 이룬 인물인
 라플라스의 규칙이 아니라, 베이즈 규칙(Bayes's Rule)이라고 불리고 있다. 그리고
 그 규칙은 기존 믿음과 관찰된 증거를 어떻게 결합할 것인가 하는 문제에 놀라울
 만큼 간단한 해결책을 제시한다. 양쪽 확률을 그냥 곱하라는 것이다. 역사적으로
 보면, 베이즈 규칙이 사전 확률을 이용한다는 사실이 논쟁의 여지가 있다고,
 편향되었다고, 심지어 비과학적이라고 여겨질 때도 있었다.<br>
모든 순간이 똑같다면, 평균적으로 그가 도착한 시기는 장벽의 생애에서 정확히
 절반에 해당하는 시점이어야 한다. 여기에는 한 가지 역설이 있다. 시간적으로
 우리가 도착한 시점이 전혀 특별하지 않다고 가정하면, 사실상 우리 자신이 중심에
 있다고 상상하는 결과가 나온다는 것이다. 코페르니쿠스 원리는 무정보 사전
 분포(uniformative prior)라고 알려진 것을 이용하여 베이즈 규칙을 적용하여 나온
 결과임이 드러난다.<br>
우리는 '부익부 빈익빈'이라고 흔히 한탄하곤 하는데, 실제로 선호적
 연결(preferential attachment)이라는 과정은 거듭제곱 분포를 낳는 가장 확실한
 방법 중의 하나다.

Griffiths and Tenenbaum, "Optimal Predictions in Everyday Cognition"<br>
사실 가능한 규모의 범위가 대단히 넓은 무정보 사전 분포는 거듭제곱 분포를 보인다.
 그리고 모든 거듭제곱 분포에서, 베이즈 규칙은 적절한 예측 전략이 곱셈
 법칙(Multiplicative Rule)임을 시사한다. 무정보 사전 분포에서는 상수 인자가
 2이며, 그래서 코페르니쿠스 예측이 나온다. 다른 거듭제곱 분포에서는 정확히 어떤
 분포를 다루고 있느냐에 따라서 곱하는 수가 달라진다. 예를 들어, 영화 총수입은 약
 1.4다.<br>
반면에 베이즈 규칙을 사전 확률이 정규 분포인 상황에 적용할 때, 평균 법칙(Average
 Rule)이 나온다. 누군가가 평균 수명보다 젊다면, 단순히 수명이 평균이라고
 예측한다. 나이가 평균 수명에 가깝거나 평균 수명을 갓 넘어섰다면, 몇 년 더 살
 거라고 예측한다. 정규 분포를 보이는 것이 너무 길게 이어진다 싶으면 곧 끝나게
 마련이다. 반면에 거듭제곱 분포를 보이는 것은 더 길어질수록, 계속 더 길어질
 거라고 예상할 수 있다.<br>
단순히 불변인 것들도 있다. 그런 현상들을 연구한 덴마크 수학자 아그네르 크라루프
 얼랭(Agner Krarup Erlang)은 독립된 사건들 사이에 펼쳐진 간격들을 하나의 함수로
 나타냈다. 그것을 얼랭 분포(Erlang distribution)라고 한다. 완만한 언덕처럼
 솟아올랐다가 거듭제곱 분포보다는 급하지만 정규 분포보다는 완만하게 꼬리가
 늘어진다. 20세기 초에 코펜하겐 전화 회사에서 일하던 얼랭은 그 분포를 써서
 전화망에서 두 통화 사이의 기간이 얼마나 될지를 모형화했다. 그 뒤로 얼랭 분포는
 도기 계획자들과 건축가들이 자동차와 보행자의 통행량 모형을 구축하고, 네트워크
 공학자들이 인터넷의 기반 시설을 설계할 때에도 쓰였다. 방사성 붕괴가 한 예다.
 그것은 얼랭 분포가 가이거 계수기가 다음에 언제 뚜뚜 소리를 낼지를 예측하는
 완벽한 모형이라는 의미다. 또 하원의원들의 재직 기간 등 여러 가지 인간의
 행동들도 꽤 잘 기술한다. 얼랭 분포는 세 번째 유형의 예측 법칙인 덧셈
 법칙(Additive Rule)도 제시한다. 일정한 양씩 더 늘어날 뿐이라고 예측하는
 법칙이다. 사실, 지난 역사나 현재 상태와 무관하게 동일한 예측을 낳는 분포를
 통계학자들은 무기억성(memoryless)을 지닌다고 말한다. 모든 사건은 얼마나 오래
 이어지든 상관없이 언제나 끝날 확률이 똑같다.<br>
사람들이 경험을 통해 얻은 정보를 토대로 예측값을 내놓는다면, 우리는 베이즈
 규칙을 써서 사람들의 기댓값을 알아냄으로써 세계에 관한 간접적인 조사를 수행할
 수 있다. 우리의 판단은 우리의 기댓값을 드러내며, 우리의 기댓값은 우리의 경험을
 드러낸다.<br>
마시멜로를 먹는 유혹에 저항하는 능력은 적어도 어느 정도는 의지력보다는 기댓값의
 문제일 수 있다는 것이다.<br>
베이즈 규칙을 잘 적용한다는 것은 적절히 보정된 좋은 선행 확률을 지닌다는
 뜻이다.<br>
주로 관심을 가진 것을 이야기하며, 그런 것들은 흔치 않은 것들인 경향이 있다.
 사람들이 관심을 가진 것을 이야기할 때 그 이야기는 우리 경험의 통계를
 왜곡시킨다. 언론에서 사건들이 언급되는 양상은 세계에서 실제로 그 사건들이
 일어나는 빈도를 반영하지 않는다. 사회학자 배리 글래스너(Barry Glassner)는
 1990년대에 걸쳐 미국의 살인 사건 발생률이 20% 감소했지만, 그 기간에 미국 언론에
 실린 총기 폭력 사고 기사는 600%가 증가했다고 말한다.

## 제7장 생각을 덜해야 할 때 _ 과적합

얼마나 열심히 생각하느냐, 그리고 얼마나 많은 요인들을 고려해야 하느냐라는 질문은
 통계학자들과 기계 학습 연구자들이 과적합(overfitting)이라고 부르는 어려운
 문제의 핵심을 이룬다. 그리고 일부러 생각을 덜 하는 것이 그 문제를 다루는 현명한
 방법임이 드러난다.<br>
통계학자들은 모형의 다양한 요인들을 예측 변수(predictor)라고 한다. 곡선에 끼워
 맞추려 하는 직선처럼 너무 단순한 모형은 편향(bias)을 드러낸다고 말한다. 너무
 복잡하게 만들어져서 자료의 작은 변화에 크게 휘둘리는 모형처럼 정반대 방향의
 오류는 분산(variance)이라고 한다. 이른바 편향-분산 트레이드오프는 모형을 좋게
 만드는 일에 심오하면서 근본적인 한계가 있음을 나타낸다.<br>
사실 어떤 왜곡된 효과를 낳지 않는 유인책이나 측정법을 내놓기란 정말 어렵다.<br>
사법기관과 군대에서는 이런 오류를 훈련 흔적(training scar)이라고 하며, 이는 준비
 상태가 과적합되는 것이 가능하다는 사실을 말해준다.<br>
기계 학습 연구자들은 과적합을 검출하는 몇 가지 확실한 전략을 찾아냈으며, 교차
 검증(cross-validation)은 그중 가장 중요한 것에 속한다. 교차 검증은 어떤 모형이
 주어진 자료에 얼마나 잘 들어맞느냐뿐 아니라, 본 적이 없는 자료에까지 얼마나 잘
 일반화시킬 수 있는지 평가하는 것을 뜻한다.<br>
컴퓨터과학자들은 제약을 가하여 모델의 복잡성에 벌점을 부여하는 원리를
 정규화(regularization)라고 한다. 1996년 생물통계학자 로버트 팁시라니(Robert
 Tibshirani)가 발견한 알고리즘은 올가미(Lasso)라고 하며, 모델이 든 모든 요인들의
 총 무게(변수들의 계수 절댓값들의 합)를 벌점으로 삼는다.<br>
신경과학자들은 뇌가 매순간에 발화하는 뉴런의 수를 최소화하려고 애쓴다는 것을
 시사하는 연구 결과들을 내놓아왔다. 언어는 또 다른 천연 올가미가 된다. 더 길게
 말을 할 때 듣는 노력과, 듣는 이의 주의 집중 시간에 가해지는 부담이 복잡성에
 벌점을 부여하기 때문이다.<br>
경제학자 해리 마코위츠(Harry M. Markowitz)는 현대 포트폴리오 이론을 개발한
 공로로 1990년에 노벨경제학상을 받았다. 그의 혁신적인 '평균-분산 포트폴리오
 최적화(mean-variance portfolio optimization)' 방법은 투자자들이 주어진 위험
 수준에서 보상을 최대화하기 위해 다양한 펀드와 자산에 최적 할당을 할 수 있는
 방법을 보여주었다.<br>
모든 유형의 기계 학습 과제에 정규화가 효과가 있다는 것은, 신중하게 생각하고
 행동하는 일을 덜함으로써 더 나은 결정을 내릴 수 있음을 시사한다. 우리가 첫
 번째로 파악한 요인이 가장 중요한 것일 가능성이 높다면, 어떤 지점을 넘어서까지
 문제를 더 깊이 생각하는 것은 시간과 노력의 낭비일 뿐만 아니라, 더 안 좋은
 해결책으로 이어질 수 있다.<br>
불확실성이 클수록, 자신이 측정할 수 있는 것과 중요한 것 사이의 격차가 클수록,
 과적합이 일어나는지 더 유념해야 한다.

## 제8장 그냥 넘어가자 _ 완화

어떤 알고리즘이 다항 시간(polynomial time)이라고 하는 것에 따라 작동한다면,
 '효율적'이라고 봐야 한다는 것이다. 그리고 효율적인 알고리즘을 써서 푸는 법을
 안다면, 그 문제는 쉬운(tractable) 것이라고 본다. 반면에 다항 시간 안에 푸는
 법을 알지 못하는 문제는 어려운(intractable) 것이라고 본다. 컴퓨터과학에서는
 효율적으로 풀 수 있는 문제들의 집합을 *P*라고 한다. 다항 시간의 약자다. 한편,
 논란 분분한 경계선에 놓은 문제들을 비결정록적 다항 시간(nondeterministric
 polynomial)의 약자를 써서 NP라고 한다. 그런 지위에 있는 문제 중 하나를
 효율적으로 풀 수 있다면, NP인 다른 문제들도 효율적으로 풀 수 있고 *P*=NP가
 된다(Cook, ⟨The Complexity of Theorem-Proving Procedures⟩). 이런 문제들을
 'NP-난해' 문제라고 한다. NP이면서 NP-난해인 것은 NP-완전(NP-complete) 문제라고
 한다. *P*와 NP의 쉬운 입문서도 있다. Fortnow, 《*The Golden Ticket: P, NP, and
 the Search for the Impossible*》. 2003년에는 스도쿠가 NP-완전임이 밝혀졌고(Yato
 and Seta, ⟨Complexity and Completeness⟩), 설령 다음에 어떤 조각이 나올지
 완벽하게 알고 있다고 해도 테트리스의 지워지는 줄 수를 최대화하는 문제도
 그렇다는 것이 드러났다(Demaine, Hohenberger, and Liben-Nowell, ⟨Tetris Is Hard,
 Even to Approximate⟩). 2012년에는 ⟨슈퍼마리오 브라더스⟩ 같은 플랫폼 게임에서 한
 레벨을 끝내는 경로가 존재하는지를 결정하는 문제도 공식적으로 이 목록에
 포함되었다(Aloupis, Demaine, and Guo, ⟨Classic Nintendo Games are (NP-)
 Hard⟩).<br>
Shaw, 《*An Introduction to Relaxation Methods; Henderson, Discrete Relaxation
 Techniques*》. 주의해야 할 것은, 긴장을 푸는 독서라고 보기 어려울 만치 수학으로
 가득하다.<br>
컴퓨터과학에서 완화의 가장 단순한 형태 중의 하나는 제약 조건 완화(Constraint
 Relaxation)라는 것이다. 이 기법은 문제의 제약 조건들 중에서 일부를 제거하여,
 문제를 원하는 형태로 만든 뒤에 푸는 것이다. 그럼으로써 얼마간 진척을 이룬 뒤,
 제약 조건들을 다시 추가하려 시도한다. 가령, 외판원이 같은 도시를 두 번 이상
 들르는 것을 허용하고 자유롭게 되돌아가는 것을 허용함으로써, 순회 외판원 문제를
 완화할 수 있다. 이 더 느슨한 규칙들 하에서 가장 짧은 경로를 찾다 보면 최소
 비용 신장 트리(Minimum Spanning Tree, MST)라는 것이 나온다.<br>
순회 외판원 문제를 전반적으로 살펴보고 싶다면 다음 문헌 참조. Cook, 《*In
 Pursuit of the Traveling Salesman*》. 좀 더 깊이 다룬 내용을 원하는 독자를 위한
 책도 있다. Lawler et al., 《*The Traveling Salesman Problem*》.

## 제9장 우연에 맡겨야 할 때 _ 무작위성

## 제10장 어떻게 연결할 것인가 _ 네트워킹

## 제11장 남들의 마음 _ 게임 이론

